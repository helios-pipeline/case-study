import{_ as c,e as n,f as l,g as e,N as a,m as s,u as d,c as i,o as h}from"./chunks/framework.CE9GIcbU.js";const o="/case-study/assets/core_full_color.BKwek0XW.png",u="/case-study/assets/core_clickhouse_highlight.ChTpqpAh.png",p="/case-study/assets/core_connector_highlight.DIwLuj7u.png",m="/case-study/assets/kinesis_integration1.CxipKTy_.png",g="/case-study/assets/kinesis_integration2.vj_pjSy2.png",f="/case-study/assets/core_client_server_highlight.D5vFvcJP.png",G=JSON.parse('{"title":"Helios Architecture","description":"","frontmatter":{},"headers":[],"relativePath":"helios-architecture.md","filePath":"helios-architecture.md"}'),_={name:"helios-architecture.md"},b=e("h1",{id:"helios-architecture",tabindex:"-1"},[s("Helios Architecture "),e("a",{class:"header-anchor",href:"#helios-architecture","aria-label":'Permalink to "Helios Architecture"'},"​")],-1),y=e("p",null,"To meet the requirements of Amazon Kinesis users looking to explore and analyze their event streams, Helios is built around three key components:",-1),v={class:"icon-list"},w=e("span",null,[e("strong",null,"Storage"),s(" - A database optimized for querying streaming data, specifically an Online Analytical Processing (OLAP) database capable of handling high-volume, real-time data ingestion, and delivering fast query performance for analytical workloads.")],-1),k=e("span",null,[e("strong",null,"Connection"),s(" - An ingestion mechanism to efficiently transfer events from Kinesis streams into our chosen database.")],-1),A=e("span",null,[e("strong",null,"Interface"),s(" - A user-friendly graphical interface allowing users to conduct analyses and visualize results.")],-1),T=i('<p><img src="'+o+'" alt="Core Arch"></p><p>Given that potential Helios users are already leveraging Amazon Kinesis, it made sense to host all of Helios&#39; infrastructure within the AWS ecosystem.</p><p>In the following section, we will dive into the specific services we chose, explaining how each component contributes to Helios&#39; functionality and performance.</p><p>Our design decisions and their associated tradeoffs will be explored in the “Building Helios: Design Choices” section of the case study, while this section is focused on how we architected Helios.</p><h2 id="storage" tabindex="-1">Storage <a class="header-anchor" href="#storage" aria-label="Permalink to &quot;Storage&quot;">​</a></h2><p>Tying back to our example use case of e-commerce user analytics, we required a database optimized for analytical queries. A typical analytical query might ask, &quot;What is the average order value for customers who used a discount code in the past hour?&quot; Such queries demand specific capabilities from our database.</p><p>As defined in &quot;Designing Data-Intensive Applications&quot; (DDIA), analytical queries typically scan millions of records, reading only a few columns per record, and calculate aggregate statistics rather than returning raw data. This definition guided our approach to storage architecture.</p><p>Databases typically fall into two categories: <strong>Online Analytical Processing (OLAP)</strong> and <strong>Online Transaction Processing (OLTP)</strong>, each optimized for distinct use cases. <strong>OLAP</strong> systems, primarily used for analytics, are designed to process millions of records per query. In contrast, <strong>OLTP</strong> systems typically process small numbers of records per query using keys and indexes for quick data retrieval. The fundamental difference lies in their access patterns: OLTP prioritizes small-scale transactions, while OLAP focuses on large-scale data analysis.</p><p>Ultimately, we chose ClickHouse as our OLAP database to power Helios&#39; analytical capabilities. <a href="./building-helios#choosing-a-database">Later</a> in this case study, we will provide a detailed exploration of our database selection process, including the factors that influenced our decision.</p><p>The following diagram illustrates our storage architecture:</p><h3 id="clickhouse-database-server" tabindex="-1">ClickHouse Database Server <a class="header-anchor" href="#clickhouse-database-server" aria-label="Permalink to &quot;ClickHouse Database Server&quot;">​</a></h3><p><img src="'+u+'" alt="Clickhouse Arch"></p><p>The main functions of the ClickHouse database are to store event data consumed from Kinesis streams and to make this data available for querying. The database is deployed on an Amazon EC2 instance (i.e. virtual server).</p><p>With storage in place, the next phase of our architecture design was to implement an integration between a user’s Amazon Kinesis streams and the ClickHouse instance.</p><h2 id="connection" tabindex="-1">Connection <a class="header-anchor" href="#connection" aria-label="Permalink to &quot;Connection&quot;">​</a></h2><p><img src="'+p+'" alt="Connection Arch"></p><p>Efficiently transferring events from Kinesis streams to our ClickHouse database presented a challenge. We needed a solution that could handle high-volume data ingestion, perform necessary decoding, and ensure reliable delivery.</p><p>To address this, we developed a custom AWS Lambda function as our stream processor. This approach allows us to:</p>',18),C={class:"icon-list"},I=e("span",null,"Decode and parse Kinesis event data",-1),H=e("span",null," Implement custom error handling",-1),q=e("span",null," Dynamically map data to appropriate ClickHouse tables",-1),P=e("span",null," Perform efficient inserts",-1),S=e("p",null,"By leveraging Lambda, we created a flexible and scalable solution tailored to our specific data processing needs. Let's explore how this custom processor works in detail.",-1),x=e("h3",{id:"",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#","aria-label":'Permalink to ""'},"​")],-1),D=e("h3",{id:"kinesis-to-clickhouse-integration",tabindex:"-1"},[s("Kinesis to ClickHouse Integration "),e("a",{class:"header-anchor",href:"#kinesis-to-clickhouse-integration","aria-label":'Permalink to "Kinesis to ClickHouse Integration"'},"​")],-1),L=e("p",null,"Helios’ Lambda Processor is an AWS serverless function that serves as a connector between Amazon Kinesis event streams and ClickHouse tables. The Lambda’s main roles are to decode the events from the Kinesis stream and insert them into the ClickHouse database. The full process involves retrieving table information, preparing data for batch insertion, and attempting to insert the data into ClickHouse.",-1),K=i('<p><img src="'+m+'" alt="Kinesis Integration 1"></p><p><img src="'+g+'" alt="Kinesis Integration 2"></p><p>Once the Lambda decodes the payload from a stream, the data needs to be sent to the associated destination table within Clickhouse. To retrieve the table ID, the Lambda interacts with a key-value database, DynamoDB, which contains a mapping of stream IDs to table IDs.</p><p>In the DynamoDB table we associate one AWS Kinesis stream to one Clickhouse table. This not only eliminates potential schema errors when ingesting data from multiple streams, but also prevents human error if users try to connect multiple streams to one table.</p><p>While the storage and connection components form the backbone of Helios, the analysis layer serves as the user-facing interface, bridging the gap between raw data and actionable insights.</p><h2 id="interface" tabindex="-1">Interface <a class="header-anchor" href="#interface" aria-label="Permalink to &quot;Interface&quot;">​</a></h2><h3 id="application-server" tabindex="-1">Application Server <a class="header-anchor" href="#application-server" aria-label="Permalink to &quot;Application Server&quot;">​</a></h3><p><img src="'+f+'" alt="App Server"></p><p>The Helios web application, hosted on an Amazon EC2 instance, serves as the primary interface for users. Implemented with a Flask backend and a React frontend, its core features include:</p>',9),O={class:"icon-list"},z=e("span",null,"An interactive SQL console for querying data from event streams, enabling real-time data analysis",-1),W=e("span",null,"An interface for connecting a data source, such as a Kinesis stream, to the Helios architecture",-1),N=e("p",null,[s("Now that you have a good understanding of how Helios works, in the next section we will cover why we designed it in this way as well as the trade-offs made throughout the building of Helios. Here is our architecture so far: "),e("img",{src:o,alt:"Core Arch"})],-1);function B(V,E,j,$,J,R){const t=n("Icon"),r=n("TippyWrapper");return h(),l("div",null,[b,y,e("div",v,[e("p",null,[a(t,{name:"CircleStackIcon"}),w]),e("p",null,[a(t,{name:"LinkIcon"}),k]),e("p",null,[a(t,{name:"WindowIcon"}),A])]),T,e("div",C,[e("p",null,[a(t,{name:"DocumentMagnifyingGlassIcon"}),I]),e("p",null,[a(t,{name:"ExclamationTriangleIcon"}),H]),e("p",null,[a(t,{name:"TableCellsIcon"}),q]),e("p",null,[a(t,{name:"ArrowDownOnSquareIcon"}),P])]),S,x,D,L,e("p",null,[s("Using an event-based trigger, the function ingests "),a(r,{content:"In Amazon Kinesis, this is formally called a 'record'. However, for consistency and clarity in our discussion, we will continue to refer to it as an 'event' throughout this case study."},{default:d(()=>[s("event data")]),_:1}),s(" from AWS Kinesis streams, and decodes the Kinesis event payload into a JSON object.")]),K,e("div",O,[e("p",null,[a(t,{name:"CommandLineIcon"}),z]),e("p",null,[a(t,{name:"LinkIcon"}),W])]),N])}const U=c(_,[["render",B]]);export{G as __pageData,U as default};
